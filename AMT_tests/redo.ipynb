{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 216 files\n",
      "Validation set: 27 files\n",
      "Test set: 27 files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths to original data\n",
    "source_wav_folder = '/home/ionan/dev/data/processed_MUS/audio'\n",
    "source_txt_folder = '/home/ionan/dev/data/processed_MUS/text'\n",
    "\n",
    "# Paths to split datasets\n",
    "train_folder = '/home/ionan/dev/data/processed_MUS/train'\n",
    "val_folder = '/home/ionan/dev/data/processed_MUS/val'\n",
    "test_folder = '/home/ionan/dev/data/processed_MUS/test'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(val_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "# Get all .wav and .txt files\n",
    "wav_files = sorted([f for f in os.listdir(source_wav_folder) if f.endswith('.wav')])\n",
    "txt_files = sorted([f for f in os.listdir(source_txt_folder) if f.endswith('.txt')])\n",
    "\n",
    "# Ensure corresponding text files exist\n",
    "wav_files = [f for f in wav_files if f.replace('.wav', '.txt') in txt_files]\n",
    "\n",
    "# Split the dataset (80% train, 10% val, 10% test)\n",
    "train_wav, test_wav = train_test_split(wav_files, test_size=0.2, random_state=42)\n",
    "val_wav, test_wav = train_test_split(test_wav, test_size=0.5, random_state=42)\n",
    "\n",
    "# Function to move .wav and corresponding .txt to target folder\n",
    "def move_files(wav_files, source_wav_folder, source_txt_folder, target_folder):\n",
    "    for wav_file in wav_files:\n",
    "        txt_file = wav_file.replace('.wav', '.txt')\n",
    "        shutil.copy(os.path.join(source_wav_folder, wav_file), target_folder)\n",
    "        shutil.copy(os.path.join(source_txt_folder, txt_file), target_folder)\n",
    "\n",
    "# Move files to respective directories\n",
    "move_files(train_wav, source_wav_folder, source_txt_folder, train_folder)\n",
    "move_files(val_wav, source_wav_folder, source_txt_folder, val_folder)\n",
    "move_files(test_wav, source_wav_folder, source_txt_folder, test_folder)\n",
    "\n",
    "print(f\"Train set: {len(train_wav)} files\")\n",
    "print(f\"Validation set: {len(val_wav)} files\")\n",
    "print(f\"Test set: {len(test_wav)} files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Parameters for CQT feature extraction\n",
    "hop_length_in = 512\n",
    "n_bins_in = 252\n",
    "bins_octaves_in = 36\n",
    "win_len = 512 / 16000  # Assuming 16kHz sampling rate\n",
    "number_notes = 88  # Piano has 88 keys\n",
    "\n",
    "# Paths to datasets\n",
    "train_folder = '/home/ionan/dev/data/processed_MUS/train'\n",
    "val_folder = '/home/ionan/dev/data/processed_MUS/val'\n",
    "test_folder = '/home/ionan/dev/data/processed_MUS/test'\n",
    "\n",
    "# Function to extract CQT features\n",
    "def extract_cqt(wav_file, sr=16000):\n",
    "    y, sr = librosa.load(wav_file, sr=sr)\n",
    "    cqt = np.abs(librosa.cqt(y, sr=sr, hop_length=hop_length_in, n_bins=n_bins_in, bins_per_octave=bins_octaves_in)).T\n",
    "    return cqt\n",
    "\n",
    "# Compute global min and max based only on training set\n",
    "def compute_min_max(train_folder):\n",
    "    min_X = []\n",
    "    max_X = []\n",
    "    wav_files = [f for f in os.listdir(train_folder) if f.endswith('.wav')]\n",
    "\n",
    "    for wav_file in wav_files:\n",
    "        cqt_feat = extract_cqt(os.path.join(train_folder, wav_file))\n",
    "        min_X.append(np.min(cqt_feat))\n",
    "        max_X.append(np.max(cqt_feat))\n",
    "\n",
    "    global_min_train = min(min_X)\n",
    "    global_max_train = max(max_X)\n",
    "\n",
    "    return global_min_train, global_max_train\n",
    "\n",
    "# Compute the global min/max using only the training set\n",
    "global_min_train, global_max_train = compute_min_max(train_folder)\n",
    "np.save('global_min_train.npy', global_min_train)\n",
    "np.save('global_max_train.npy', global_max_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize CQT features based on training min/max\n",
    "def normalize_with_min_max(cqt_feat, global_min, global_max):\n",
    "    return (cqt_feat - global_min) / (global_max - global_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to align labels (onset/offset times from .txt) with CQT features\n",
    "def align_labels(txt_file, cqt_feat, win_len):\n",
    "    num_frames = cqt_feat.shape[0]\n",
    "    vector_aux = np.arange(1, num_frames + 1) * win_len  # Time vector for each frame\n",
    "    labels = np.zeros((num_frames, number_notes))\n",
    "\n",
    "    with open(txt_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove whitespace\n",
    "            if not line or \"OnsetTime\" in line:\n",
    "                continue  # Skip empty lines or header\n",
    "\n",
    "            onset_time, offset_time, pitch = map(float, line.split())\n",
    "            pitch = int(pitch) - 21  # Adjust pitch range (MIDI 21 is A0)\n",
    "            onset_idx = np.searchsorted(vector_aux, onset_time)\n",
    "            offset_idx = np.searchsorted(vector_aux, offset_time)\n",
    "            labels[onset_idx:offset_idx, pitch] = 1\n",
    "\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and label all data (train, val, test)\n",
    "def process_and_save_data(data_folder, global_min, global_max, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    wav_files = [f for f in os.listdir(data_folder) if f.endswith('.wav')]\n",
    "\n",
    "    for wav_file in wav_files:\n",
    "        base_name = os.path.splitext(wav_file)[0]\n",
    "        wav_path = os.path.join(data_folder, wav_file)\n",
    "        txt_path = os.path.join(data_folder, base_name + '.txt')\n",
    "\n",
    "        # Extract and normalize features\n",
    "        cqt_feat = extract_cqt(wav_path)\n",
    "        cqt_normalized = normalize_with_min_max(cqt_feat, global_min, global_max)\n",
    "\n",
    "        # Align labels\n",
    "        labels = align_labels(txt_path, cqt_normalized, win_len)\n",
    "\n",
    "        # Save features and labels\n",
    "        np.save(os.path.join(output_folder, base_name + '_X.npy'), cqt_normalized)\n",
    "        np.save(os.path.join(output_folder, base_name + '_y.npy'), labels)\n",
    "\n",
    "# Apply normalization and label alignment for training, validation, and test sets\n",
    "global_min_train = np.load('global_min_train.npy')\n",
    "global_max_train = np.load('global_max_train.npy')\n",
    "\n",
    "process_and_save_data(train_folder, global_min_train, global_max_train, '/home/ionan/dev/data/processed_MUS/processed_split/train')\n",
    "process_and_save_data(val_folder, global_min_train, global_max_train, '/home/ionan/dev/data/processed_MUS/processed_split/val')\n",
    "process_and_save_data(test_folder, global_min_train, global_max_train, '/home/ionan/dev/data/processed_MUS/processed_split/test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file pairs :  216.0\n",
      "Validation file pairs :  27.0\n",
      "Test file pairs :  27.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Training file pairs : \", len(os.listdir(train_folder)) / 2)\n",
    "print(\"Validation file pairs : \", len(os.listdir(val_folder)) / 2)\n",
    "print(\"Test file pairs : \", len(os.listdir(test_folder)) / 2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
