{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters for CQT feature extraction\n",
    "hop_length_in = 512\n",
    "n_bins_in = 252\n",
    "bins_octaves_in = 36\n",
    "win_len = 512 / 16000  # Assuming 16kHz sampling rate\n",
    "number_notes = 88  # Piano has 88 keys\n",
    "length_per_file = 4000000\n",
    "\n",
    "# Paths to files\n",
    "source_wav_folder = '/home/ionan/dev/data/processed_MUS'  # Path to your WAV files\n",
    "source_txt_folder = '/home/ionan/dev/data/processed_MUS'  # Path to your TXT files\n",
    "output_folder = '/home/ionan/dev/data/processed_MUS/labeled'  # Path to save processed data\n",
    "\n",
    "# Load global min and max for normalization\n",
    "global_min = np.load('global_min.npy')\n",
    "global_max = np.load('global_max.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract CQT features and normalize them\n",
    "def extract_and_normalize_cqt(wav_file, sr=16000):\n",
    "    y, sr = librosa.load(wav_file, sr=sr)\n",
    "    cqt = np.abs(librosa.cqt(y, sr=sr, hop_length=hop_length_in, n_bins=n_bins_in, bins_per_octave=bins_octaves_in)).T\n",
    "    # Apply min-max normalization\n",
    "    cqt_normalized = (cqt - global_min) / (global_max - global_min)\n",
    "    return cqt_normalized\n",
    "\n",
    "# Function to align labels (onset/offset times) with the audio features\n",
    "def align_labels(txt_file, cqt_feat, win_len):\n",
    "    # Number of frames in the CQT feature\n",
    "    num_frames = cqt_feat.shape[0]\n",
    "    vector_aux = np.arange(1, num_frames + 1) * win_len  # Time vector for each frame\n",
    "    labels = np.zeros((num_frames, number_notes))\n",
    "\n",
    "    with open(txt_file, 'r') as file:\n",
    "        for index, line in enumerate(file):\n",
    "            if \"OnsetTime\" not in line and line.__len__() > 0:\n",
    "                line = line.strip()  # Remove leading/trailing whitespace\n",
    "                if not line:  # Skip empty lines\n",
    "                    continue\n",
    "                onset_time, offset_time, pitch = map(float, line.split())\n",
    "                pitch = int(pitch) - 21  # Adjust pitch range (MIDI 21 is A0)\n",
    "                # Find corresponding frame indices for onset and offset times\n",
    "                onset_idx = np.searchsorted(vector_aux, onset_time)\n",
    "                offset_idx = np.searchsorted(vector_aux, offset_time)\n",
    "                labels[onset_idx:offset_idx, pitch] = 1\n",
    "\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the output directory exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Example of a list of files (you can dynamically generate this list)\n",
    "wav_files = sorted([f for f in os.listdir(source_wav_folder) if f.endswith('.wav')])\n",
    "txt_files = sorted([f for f in os.listdir(source_txt_folder) if f.endswith('.txt')])\n",
    "cqt_error_files = []\n",
    "label_error_files = []\n",
    "# Process each file in the list\n",
    "for wav_file, txt_file in zip(wav_files, txt_files):\n",
    "    wav_path = os.path.join(source_wav_folder, wav_file)\n",
    "    txt_path = os.path.join(source_txt_folder, txt_file)\n",
    "    try :\n",
    "        # Extract and normalize CQT features\n",
    "        cqt_feat = extract_and_normalize_cqt(wav_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {wav_file}: {e}\")\n",
    "        cqt_error_files.append(wav_file)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Align labels with the CQT features\n",
    "        labels = align_labels(txt_path, cqt_feat, win_len)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {txt_file}: {e}\")\n",
    "        label_error_files.append(wav_file)\n",
    "        continue\n",
    "    # Save the features and labels\n",
    "    base_filename = os.path.splitext(wav_file)[0]\n",
    "    np.save(os.path.join(output_folder, f'{base_filename}_X.npy'), cqt_feat)\n",
    "    np.save(os.path.join(output_folder, f'{base_filename}_y.npy'), labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270.0\n"
     ]
    }
   ],
   "source": [
    "#print the number of files in the source_wav_folder\n",
    "print(len(os.listdir(\"/home/ionan/dev/data/processed_MUS/labeled\")) / 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
